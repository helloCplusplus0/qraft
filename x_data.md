# Qraft 6.0｜“算法层做到极致”的系统设计（可落地版）

> 目标：在**不训练模型**的前提下，用**确定性算法**把时序/交易数据“榨干”：多尺度加工 → 结构识别 → 策略信号 → 成本/执行意识 → 鲁棒评估 → 可解释与可审计产物；把“深度上下文”打包给 LLM，仅做解释/推理/交互。

---

## 0. 顶层原则

* **确定性优先**：所有输出可复现、可审计（数据/参数/代码版本化）。
* **执行意识**：任何信号从一开始就考虑**交易成本/滑点/延迟/可成交性**。
* **多尺度与体制化**：短/中/长周期并行，识别\*\*市场状态（regime）\*\*并切换。
* **鲁棒为王**：稳定性、跨期/跨市场有效性、参数敏感性 > 单点收益。
* **LLM 友好**：核心产物结构化（JSON/Parquet），附自然语言摘要与证据链。

---

## 1. 数据与计算基座

### 1.1 数据模型与谱系

* 统一 **Event/Bar/Trade/Quote/OrderBook** 抽象；Arrow schema 固化。
* 时间轴规范：`ts[UTC] + exchange_cal`；`sid` 唯一键；多资产/多市场可并行。
* **版本化**：`dataset@ver`、`feature_pipeline@ver`、`cost_model@ver`。
* **谱系记录**：来源 → 清洗 → 对齐 → 特征 → 信号 → 组合 → 回测 → 报表。

### 1.2 计算引擎与加速

* **列式内存**：Polars/Arrow；批量计算优先向量化。
* **就地数据库**：DuckDB（研究）/ClickHouse（生产）。
* **并行**：Ray/Polars streaming；I/O 与计算分流。
* **热点**：高频指标/撮合仿真可下沉 Rust/C++（pyo3/Cython）。

---

## 2. 数据加工（极致版）

### 2.1 清洗/对齐

* 缺失/异常：winsorize、z-score 滤波、价量联动过滤、箱线图阈值。
* 去复权/合约连续：期货主力/指数合成、股息/分拆处理。
* **多频聚合**：tick→1s/1m/5m/1h/1d；支持滚动窗口对齐（左闭右开）。

### 2.2 特征库（可扩展）

* **价量基础**：MA/EMA/KAMA、RSI/CCI、ATR、VWAP、OBV、成交额/换手。
* **波动/相关**：Realized Vol、Parkinson/Garman-Klass、加权相关、互信息。
* **微观结构**：价差/盘口不平衡（Order Imbalance）、Kyle/Amihud 冲击度、签名功率。
* **形态与结构**：趋势斜率/R²、拐点/摆动、布林带触碰、箱体宽度。
* **统计关系**：协整（Engle–Granger/ADF）、半衰期、Hurst/ADF 单位根、变点。
* **跨资产/跨合约**：跨期价差、跨品种比价、合成对冲篮子。

> 产物：`FeatureFrame(index=[ts,sid], columns=[...], meta={universe,freq,pipeline_ver})`

---

## 3. 结构识别与市场状态（Regime）

### 3.1 震荡/趋势/突破判别（示例）

* **趋势强度**：`TS = |slope(close_window)| / std(residual)`；`TS>τ` 判定趋势。
* **震荡箱体**：`range = max-min` 与 `ATR` 比值；多次支撑/阻力触达计数。
* **突破/假突破**：`close` 突破箱体 ±k·ATR；回落阈值判假突破。

### 3.2 变点/体制切换

* **变点**：基于残差方差/均值/相关结构的 BOCPD 或能量统计（算法化实现，无训练）。
* **体制标签**：`{trend_up, trend_down, range, high_vol, low_liq}` 多标签可并存。
* **体制自适应参数**：在不同 regime 下切换不同网格间距/回撤阈值/开平仓规则。

> 产物：`RegimeFrame(ts,sid → regime_tags, confidence, evidence)`

---

## 4. 策略信号（规则/算法，不训练）

### 4.1 因子到信号

* **阈值型**：如 `zscore(spread) ∈ [-1.5,-0.5]` 开多、`[0.5,1.5]` 平。
* **区间套利**：箱体上下沿+ATR 动态网格；**价差≥成本+安全边际** 才成交。
* **均值回归**：协整对/篮子，半衰期自适应仓位；执行带 VWAP 限价。
* **动量/反转**：多尺度动量一致性过滤 + 成本感知（见 5）。

### 4.2 组合与配比（无模型优化版）

* **目标波动率**：`w_i ∝ signal_i / realized_vol_i`，控制组合年化波动=目标值。
* **风险预算**：等风险贡献（ERC）近似解；行业/合约/方向上限。
* **去相关与去重**：信号间相关阈值/Top-N 重叠率约束，避免“同质化曝险”。

> 产物：`SignalFrame(ts,sid → side, score, intent_size, ttl, regime_ref)`

---

## 5. 成本/执行意识（从一开始就内嵌）

### 5.1 成本模型

* **显性**：佣金、交易税、经纪商费。
* **隐性**：点差、冲击（Amihud/Kyle 估计）、排队/延迟成交（queue model）。
* **滑点**：基于盘口深度/近邻成交回放估计分布，生成 `slippage ~ D(ts,sid,liq)`。

### 5.2 可成交性与路由

* **参与率目标**：POV/TWAP/VWAP，约束每根 bar 的成交量上限。
* **限价保护**：仅当 `edge >= costs + buffer` 才发单；未成交自动撤改。
* **可执行净优势**：`edge_exec = theo_edge - expected_costs - risk_buffer`，edge<0 禁止下单。

---

## 6. 鲁棒性与评估（极致版）

### 6.1 稳定性面板

* **滚动回测**：不同起止/窗长（IS/OOS）分布；**分布而非点估计**。
* **跨市场/跨体制**：不同品种、不同 regime 子集表现与方差比较。
* **参数敏感性**：±10–50% 网格化，观察收益/夏普/回撤曲面；寻找**平顶区**（Robust sweet spot）。

### 6.2 多重检验与现实检验

* **SPA/White’s Reality Check**（简化实现）：对候选策略集校正显著性。
* **成本/延迟压力**：成本×\[0.5,1.5]、滑点+X bp、撮合延迟+Y ms 的压力测试。
* **事件过滤**：禁用极端事件日期的“幸存者贡献”，评估真实度。

### 6.3 风险与归因

* 指标：收益/波动/夏普/卡玛/最大回撤/MAR/偏度/峰度/换手/成本占比。
* 归因：Brinson/因子暴露、来源分解（edge vs. timing vs. liquidity）。

> 产物：`ReportBundle = {metrics.csv, sensitivity.parquet, regime_breakdown.csv, trades.parquet, attribution.csv}`

---

## 7. 在线化与自适应（不训练也能“学习”）

* **滑动窗口自更新**：特征参数、ATR/半衰期/成本模型每日滚动更新。
* **体制感知切换**：regime 变更 → 切换对应参数模板（JSON）。
* **健康监控**：日度 DSR/收益偏差、成交偏离、成本抬升预警。

---

## 8. 对 LLM 的“深度上下文”打包

### 8.1 结构化上下文

* **Evidence JSON**（每个信号的证据链）：

```json
{
  "ts":"2025-08-19T03:00:00Z","sid":"FUT_XYZ",
  "regime":["range","low_vol"],"features":{"atr":0.8,"box_width":2.1,"z_spread":-1.7},
  "costs":{"commission_bps":2,"slippage_bps":5,"impact_bps":7},
  "edge":{"theo":28,"exec":13,"buffer":5},
  "decision":{"action":"buy","size":0.35,"ttl":"2h","rationale":"box lower + z<-1.5 with edge>cost+buffer"}
}
```

* **Tearsheet 摘要**（自然语言2–3段） + 指标表格/图的引用句柄。

### 8.2 LLM 使用边界

* LLM 仅做**解释/问答/对比/策略假设生成**；**不允许**覆盖成本/风控硬约束。

---

## 9. API / 协议（与 Qraft 其余层对接）

### 9.1 算法层输入

```yaml
RunSpec:
  universe: [symbols...]
  freq: 1m
  span: {start: 2023-01-01, end: 2025-08-01}
  feature_pipeline_ver: v3.2
  cost_model_ver: cm-2025-07
  regimes: [trend, range, high_vol, low_liq]
```

### 9.2 输出（供回测/执行/报告/LLM）

* `FeatureFrame.parquet`, `RegimeFrame.parquet`, `SignalFrame.parquet`
* `TradesSim.parquet`（Nautilus 回放结果）
* `ReportBundle/…`（指标、敏感性、归因、图表）

---

## 10. 性能/工程落地要点

* **批处理**：Polars + DuckDB 子查询；大任务分片（按 `sid`/时间块）。
* **缓存**：特征层与成本层设置内容寻址缓存（hash(data+params)）。
* **并发**：Ray/多进程；I/O 与 CPU 计算分离；异步写 ClickHouse。
* **下沉**：微观结构指标、撮合回放、协整检验可用 Rust（pyo3）实现。
* **测试/审计**：

  * 单元：指标数学恒等、边界条件
  * 回测一致性：固定随机种子/撮合路径重放
  * 回归：每次改动与基线曲线/指标 diff

---

## 11. 策略库（无训练的“经典可叠加”模块）

* **震荡网格（成本感知）**：动态间距= f(ATR, spread, liq)，仅当 `edge_exec>0`。
* **价差均值回归**：协整 + 半衰期 → 动态杠杆与止损；再平衡成本阈值。
* **突破动量**：箱体突破 + 体制确认 + 回撤保护；持仓 TTL 与分批止盈。
* **跨期/跨品种套利**：合约规则适配 + 资金/保证金约束 + 事件日停用。
* **事件空窗**：高冲击时段（开收盘/数据公布）自动降杠杆或清仓。

> 每个策略均以 **规则 JSON** + **执行模板** 表达，便于 LLM 生成/人审。

---

## 12. MVP → 强化路径

* **MVP（4–8 周）**：清洗/特征库 v1、regime 判别、3 个策略模板、成本模型 v1、报告与敏感性面板、Nautilus 接口、LLM 解释。
* **增强**：微观结构指标下沉 Rust、变点/体制引擎 v2、Reality Check、跨市场适配、在线自适应、TUI 作业编排与监控。

---

### 一句话总结

> **把“模型黑箱”拆成“确定性算法+体制化流程”**：用多尺度特征、体制识别、成本/执行意识和鲁棒评估，做出**可复现、可上线**的策略信号；再把“证据链”打包给 LLM 做解释与交互。这样既能**逼近并在若干套利/对冲场景超越**训练模型的实战效果，又避免黑箱过拟合与工程风险。

好问题 👍。
你要做到 **算法层面极致的数据处理与分析**，不一定要完全“手写”，业界其实有一些 **专门的算法库 / 工具集**，它们正是为 **时序数据、结构识别、模式发现、因果分析** 等环节服务的。下面我帮你系统梳理：

---

## 🔹 系统全面的算法工具分类

### 1. **数据表象提取（Feature Extraction / Representation）**

目标：把原始时序或金融数据转化为可操作的特征。

* **tsfresh**（Python）：自动化特征提取，几百种统计特征。
* **Kats (Facebook)**：轻量级时序分析库，含特征提取、预测、异常检测。
* **featuretools**：自动化特征工程，支持深度特征合成。
* **cesium**：面向时序科学数据的特征提取。

👉 工具价值：减少手写低层特征的工作，让你专注高层逻辑。

---

### 2. **结构识别（Clustering / Segmentation / Topology）**

目标：识别数据的内在结构，划分不同状态/模式。

* **ruptures**：时间序列分段/变点检测。
* **matrixprofile-ts**：模式发现与重复模式匹配。
* **hdbscan**：高维/非线性聚类，适合金融因子聚类。
* **UMAP / t-SNE**：降维与结构可视化。

👉 工具价值：帮助找到 **市场状态切换点、潜在因子簇**。

---

### 3. **模式发现（Pattern Discovery）**

目标：挖掘重复出现的形态或规律。

* **stumpy**：快速计算 Matrix Profile，用于模式/异常发现。
* **Kats (again)**：内置季节性分解、模式匹配。
* **mlfinlab**（金融因子库）：特征净化、标签生成（triple-barrier method）。

👉 工具价值：替代“裸眼看K线”，自动化找规律。

---

### 4. **因果推理（Causal Inference）**

目标：从相关走向因果。

* **DoWhy (Microsoft)**：统一的因果建模与推断框架。
* **EconML (Microsoft)**：经济学 + 机器学习的因果推断。
* **CausalNex**：基于贝叶斯网络的因果关系学习。
* **lingam**：利用独立成分分析进行因果发现。

👉 工具价值：避免被“虚假相关”误导，找到驱动市场的真实因子。

---

### 5. **异常检测（Anomaly Detection）**

目标：发现数据中的突变或罕见行为。

* **pyod**：最全的异常检测算法集合。
* **Kats**：内置时序异常检测。
* **alibi-detect**：偏向分布漂移与异常点检测。

---

### 6. **算法管道化（Pipeline + 组合）**

要做到“极致”，不是单一算法，而是 **可组合的分析流水线**：

1. **预处理**（清洗、降噪、归一化）
2. **表象提取**（统计量 + 特征库）
3. **结构识别**（聚类 / 变点检测）
4. **模式发现**（重复模式、潜在因子）
5. **因果推理**（验证驱动因素）
6. **异常检测 & 反馈**（监控）

---

## 🔹 回答你的问题

1. **是否需要手写？**

   * ✅ 常用算法（特征提取、聚类、因果推理）已有 **开源工具**，可以直接用。
   * 🚫 但是若要“极致”，往往需要 **在工具基础上做二次开发 / 定制**。
   * 举例：tsfresh 给了几百个特征 → 但你可能要 **筛选并组合**，才能贴合金融博弈。

2. **是否存在一站式工具？**

   * ❌ 没有单一工具能覆盖“表象 → 结构 → 模式 → 因果 → 反馈”全链路。
   * ✅ 你需要 **拼装工具链**（如 `tsfresh + ruptures + stumpy + DoWhy`），再在上层用 **自定义算法逻辑** 把它们串联成“极致分析器”。

---

要不要我帮你整理一个 **Qraft 6.0 专属算法工具栈清单**（类似“极致分析套件”），直接对应到你刚才说的四个环节（表象提取、结构识别、模式发现、因果推理），并标注哪些开源工具可直接用，哪些需要手写？
